/* StarPU --- Runtime system for heterogeneous multicore architectures.
 *
 * Copyright (C) 2009-2025  University of Bordeaux, CNRS (LaBRI UMR 5800), Inria
 *
 * StarPU is free software; you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as published by
 * the Free Software Foundation; either version 2.1 of the License, or (at
 * your option) any later version.
 *
 * StarPU is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
 *
 * See the GNU Lesser General Public License in COPYING.LGPL for more details.
 */

/*! \intropage{IntroExtensions, --------- StarPU Extensions ---------}

\webforeword

This part explains the advanced concepts of StarPU. It is intended for users whose applications need more than basic task submission.

You can learn more knowledge about some important and core concepts in StarPU:
<ul>
<li>
After reading Chapter \ref TasksInStarPU, you can get more
information about how to manage tasks in StarPU in Chapter \ref
AdvancedTasksInStarPU.
</li>
<li>
After reading Chapter \ref DataManagement, you can know more about
how to manage the data layout of your applications in Chapter \ref
AdvancedDataManagement.
</li>
<li>
After reading Chapter \ref Scheduling, you can get some advanced
scheduling policies in StarPU in Chapters \ref AdvancedScheduling,
\ref SchedulingContexts and \ref SchedulingContextHypervisor.
</li>
<li>
Chapter \ref HowToDefineANewSchedulingPolicy explains how to
define a StarPU task scheduling policy either in a basic
monolithic way, or in a modular way.
</li>
</ul>

Other chapters cover some further usages of StarPU.
<ul>
<li>
Chapters \ref CUDASupport and \ref OpenCLSupport show how to use
GPU devices with CUDA or OpenCL. Chapter \ref MaxFPGASupport
explains how StarPU support Field Programmable Gate Array (FPGA)
applications exploiting DFE configurations.
</li>
<li>
If you need to store more data than what the main memory (RAM) can
store, Chapter \ref OutOfCore presents how to add a new memory
node on a disk and how to use it.
</li>
<li>
Chapter \ref MPISupport shows how to integrate MPI processes in
StarPU.
</li>
<li>
Chapter \ref TCPIPSupport shows a TCP/IP server client mechanism
which can execute application across many remote cores without
dealing about data distribution.
</li>
<li>
Chapter \ref Transactions shows how to cancel a sequence of
already submitted tasks based on a just-in-time decision.
</li>
<li>
Chapter \ref FaultTolerance explains how StarPU provide supports
for failure of tasks or even failure of complete nodes.
</li>
<li>
Chapter \ref FFTSupport explains how StarPU provides a similar
library to both <c>fftw</c> and <c>cufft</c>, but by adding a
support from both CPUs and GPUs.
</li>
<li>
Chapter \ref SOCLOpenclExtensions explains how OpenCL applications
can transparently be run using StarPU, by givings unified access
to every available OpenCL device.
</li>
<li>
We propose a recursive tasks model in Chapter \ref
RecursiveTasks to enable tasks subgraphs at runtime for a more
dynamic task graph.
</li>
<li>
You can find how to partition a machine into parallel workers in
Chapter \ref ParallelWorker.
</li>
<li>
Chapter \ref InteroperabilitySupport shows how StarPU can coexist
with other parallel software elements without resulting in
computing core oversubscription or undersubscription.
</li>
<li>
Chapter \ref SimGridSupport shows you how to simulate execution on
an arbitrary platform.
</li>
<li>
Tools to help debugging applications are presented in Chapter \ref
DebuggingTools.
</li>
</ul>

And finally, chapter \ref Helpers gives a list of StarPU utility
functions.

*/
